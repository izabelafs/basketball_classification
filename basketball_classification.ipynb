{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Basketball teams classification\n\nLet's first load required libraries:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn import tree\nimport numpy as np\nfrom IPython.display import Image  \n%matplotlib inline",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## About dataset\nThis dataset is about the performance of basketball teams. The cbb.csv data set includes performance data about five seasons of 354 basketball teams. It includes the following fields:\n\nField\tDescription\nTEAM\tThe Division I college basketball school\nCONF\tThe Athletic Conference in which the school participates in (A10 = Atlantic 10, ACC = Atlantic Coast Conference, AE = America East, Amer = American, ASun = ASUN, B10 = Big Ten, B12 = Big 12, BE = Big East, BSky = Big Sky, BSth = Big South, BW = Big West, CAA = Colonial Athletic Association, CUSA = Conference USA, Horz = Horizon League, Ivy = Ivy League, MAAC = Metro Atlantic Athletic Conference, MAC = Mid-American Conference, MEAC = Mid-Eastern Athletic Conference, MVC = Missouri Valley Conference, MWC = Mountain West, NEC = Northeast Conference, OVC = Ohio Valley Conference, P12 = Pac-12, Pat = Patriot League, SB = Sun Belt, SC = Southern Conference, SEC = South Eastern Conference, Slnd = Southland Conference, Sum = Summit League, SWAC = Southwestern Athletic Conference, WAC = Western Athletic Conference, WCC = West Coast Conference)\nG\tNumber of games played\nW\tNumber of games won\nADJOE\tAdjusted Offensive Efficiency (An estimate of the offensive efficiency (points scored per 100 possessions) a team would have against the average Division I defense)\nADJDE\tAdjusted Defensive Efficiency (An estimate of the defensive efficiency (points allowed per 100 possessions) a team would have against the average Division I offense)\nBARTHAG\tPower Rating (Chance of beating an average Division I team)\nEFG_O\tEffective Field Goal Percentage Shot\nEFG_D\tEffective Field Goal Percentage Allowed\nTOR\tTurnover Percentage Allowed (Turnover Rate)\nTORD\tTurnover Percentage Committed (Steal Rate)\nORB\tOffensive Rebound Percentage\nDRB\tDefensive Rebound Percentage\nFTR\tFree Throw Rate (How often the given team shoots Free Throws)\nFTRD\tFree Throw Rate Allowed\n2P_O\tTwo-Point Shooting Percentage\n2P_D\tTwo-Point Shooting Percentage Allowed\n3P_O\tThree-Point Shooting Percentage\n3P_D\tThree-Point Shooting Percentage Allowed\nADJ_T\tAdjusted Tempo (An estimate of the tempo (possessions per 40 minutes) a team would have against the team that wants to play at an average Division I tempo)\nWAB\tWins Above Bubble (The bubble refers to the cut off between making the NCAA March Madness Tournament and not making it)\nPOSTSEASON\tRound where the given team was eliminated or where their season ended (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)\nSEED\tSeed in the NCAA March Madness Tournament\nYEAR\tSeason\nLoad Data From CSV File\nLet's load the dataset [NB Need to provide link to csv file]",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv('cbb.csv')\ndf.head()\ndf.shape\n(1406, 24)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Add Column\nNext we'll add a column that will contain \"true\" if the wins above bubble are over 7 and \"false\" if not. We'll call this column Win Index or \"windex\" for short.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df['windex'] = np.where(df.WAB > 7, 'True', 'False')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Data visualization and pre-processing\nNext we'll filter the data set to the teams that made the Sweet Sixteen, the Elite Eight, and the Final Four in the post season. We'll also create a new dataframe that will hold the values with the new column.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "f1 = df.loc[df['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\ndf1.head()\ndf1['POSTSEASON'].value_counts()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "32 teams made it into the Sweet Sixteen, 16 into the Elite Eight, and 8 made it into the Final Four over 5 seasons.\n\nLets plot some columns to understand the data better:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# notice: installing seaborn might takes a few minutes\n!conda install -c anaconda seaborn -y",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import seaborn as sns\n\nbins = np.linspace(df1.BARTHAG.min(), df1.BARTHAG.max(), 10)\ng = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=6)\ng.map(plt.hist, 'BARTHAG', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "bins = np.linspace(df1.ADJOE.min(), df1.ADJOE.max(), 10)\ng = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'ADJOE', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Pre-processing: Feature selection/extraction\nLets look at how Adjusted Defense Efficiency plots",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "bins = np.linspace(df1.ADJDE.min(), df1.ADJDE.max(), 10)\ng = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'ADJDE', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We see that this data point doesn't impact the ability of a team to get into the Final Four.\n\n## Convert Categorical features to numerical values\nLets look at the postseason:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df1.groupby(['windex'])['POSTSEASON'].value_counts(normalize=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "13% of teams with 6 or less wins above bubble make it into the final four while 17% of teams with 7 or more do.\n\nLets convert wins above bubble (winindex) under 7 to 0 and over 7 to 1:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df1['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\ndf1.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Feature selection\nLet's define feature sets, X:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\nX[0:5]\ny = df1['POSTSEASON'].values\ny[0:5]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Normalize the data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Training and test data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# We split the X into train and test to find the best k\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Validation set:', X_val.shape,  y_val.shape)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Classification",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### KNN",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 5\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh\n\nyhat = neigh.predict(X_val)\nyhat[0:5]\n\nfrom sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Validation set Accuracy: \", metrics.accuracy_score(y_val, yhat))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Accuracy",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Ks = 16\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\n\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_val)\n    mean_acc[n-1] = metrics.accuracy_score(y_val, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_val)/np.sqrt(yhat.shape[0])\n\nmean_acc",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Decision tree",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nTree # it shows the default parameters\nTree.fit(X_train,y_train)\npredTree = Tree.predict(X_val)\nprint (predTree [0:5])\nprint (y_val [0:5])\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_val, predTree))\ntree.plot_tree(Tree)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Support vector machine - SVM",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import svm\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\n#RBF\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train) \nyhat = clf.predict(X_val)\nyhat [0:5]\n\nf1_score(y_val, yhat, average='weighted') \nprint (classification_report(y_val, yhat))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#poly\nclf = svm.SVC(kernel='poly')\nclf.fit(X_train, y_train) \nyhat = clf.predict(X_val)\nyhat [0:5]\n\nf1_score(y_val, yhat, average='weighted') \n#print (classification_report(y_val, yhat))\n\nprint (classification_report(y_val, yhat))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#sigmoid\nclf = svm.SVC(kernel='sigmoid')\nclf.fit(X_train, y_train) \nyhat = clf.predict(X_val)\nyhat [0:5]\n\nf1_score(y_val, yhat, average='weighted')\n\n#Sigmoid kernel provides the best accuracy\nprint (classification_report(y_val, yhat))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#linear\nclf = svm.SVC(kernel='linear')\nclf.fit(X_train, y_train) \nyhat = clf.predict(X_val)\nyhat [0:5]\n\nf1_score(y_val, yhat, average='weighted') \nprint (classification_report(y_val, yhat))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Logistic regression",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLR\nyhat = LR.predict(X_val)\nyhat\narray(['F4', 'S16', 'E8', 'E8', 'E8', 'E8', 'S16', 'F4', 'E8', 'S16',\n       'S16', 'S16'], dtype=object)\nyhat_prob = LR.predict_proba(X_val)\nyhat_prob",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Model evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score\n# for f1_score please set the average parameter to 'micro'\nfrom sklearn.metrics import log_loss\ndef jaccard_index(predictions, true):\n    if (len(predictions) == len(true)):\n        intersect = 0;\n        for x,y in zip(predictions, true):\n            if (x == y):\n                intersect += 1\n        return intersect / (len(predictions) + len(true) - intersect)\n    else:\n        return -1",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Test set evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_df = pd.read_csv('basketball_train.csv',error_bad_lines=False)\ntest_df.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "test_df['windex'] = np.where(test_df.WAB > 7, 'True', 'False')\ntest_df1 = test_df[test_df['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\ntest_Feature = test_df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\ntest_Feature['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\ntest_X=test_Feature\ntest_X= preprocessing.StandardScaler().fit(test_X).transform(test_X)\ntest_X[0:5]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "test_y = test_df1['POSTSEASON'].values\ntest_y[0:5]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### KNN",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "k = 5\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nyhat = neigh.predict(test_X)\n\nprint(\"Test set Accuracy: \", metrics.accuracy_score(test_y, yhat))\nprint(\"Test F1-score: \", f1_score(test_y, yhat, average='weighted'))\nprint(\"Test Jaccard index: \", jaccard_index(test_y, yhat))\nTest set Accuracy:  0.6285714285714286\nTest F1-score:  0.62031212484994\nTest Jaccard index:  0.4583333333333333",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Decision tree",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 2)\nTree # it shows the default parameters\nTree.fit(X_train,y_train)\npredTree = Tree.predict(test_X)\nprint(\"Test set Accuracy: \", metrics.accuracy_score(test_y, yhat))\nprint(\"Test F1-score: \", f1_score(test_y, yhat, average='weighted'))\nprint(\"Test Jaccard index: \", jaccard_index(test_y, yhat))\nTest set Accuracy:  0.6\nTest F1-score:  0.5353383458646617\nTest Jaccard index:  0.42857142857142855",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### SVM",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "clf = svm.SVC(kernel='sigmoid')\nclf.fit(X_train, y_train) \nyhat = clf.predict(test_X)\nprint(\"Test set Accuracy: \", metrics.accuracy_score(test_y, yhat))\nprint(\"Test F1-score: \", f1_score(test_y, yhat, average='weighted'))\nprint(\"Test Jaccard index: \", jaccard_index(test_y, yhat))\nTest set Accuracy:  0.6\nTest F1-score:  0.5353383458646617\nTest Jaccard index:  0.42857142857142855",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Logistic Regression",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nyhat = LR.predict(test_X)\nyhat_prob = LR.predict_proba(test_X)\n\nprint(\"Test set Accuracy: \", metrics.accuracy_score(test_y, yhat))\nprint(\"Test F1-score: \", f1_score(test_y, yhat, average='weighted'))\nprint(\"Test Jaccard index: \", jaccard_index(test_y, yhat))\nprint(\"Test LogLoss: \",log_loss(test_y, yhat_prob))\nTest set Accuracy:  0.6857142857142857\nTest F1-score:  0.6899251963841629\nTest Jaccard index:  0.5217391304347826\nTest LogLoss:  1.03718699059278",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}